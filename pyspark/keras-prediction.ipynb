{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elephas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import window, avg, count\n",
    "from pyspark.sql import types as T\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# from pyspark.mllib.linalg import Matrix, Matrices, Vectors, SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.ml.linalg import Matrix, Matrices, Vectors, SparseVector, DenseVector, VectorUDT\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "from elephas.ml_model import ElephasEstimator, ElephasTransformer\n",
    "from elephas.spark_model import SparkMLlibModel\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Streaming\")\n",
    "         .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.4.1,org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read our processed time windows from mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o86.load.\n: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=165.22.199.122:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.SocketTimeoutException: connect timed out}}]\n\tat com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:182)\n\tat com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)\n\tat com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:136)\n\tat com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:94)\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:249)\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:172)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:184)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:153)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:148)\n\tat com.mongodb.spark.MongoConnector$$anonfun$1.apply(MongoConnector.scala:237)\n\tat com.mongodb.spark.MongoConnector$$anonfun$1.apply(MongoConnector.scala:237)\n\tat com.mongodb.spark.MongoConnector$$anonfun$withDatabaseDo$1.apply(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector$$anonfun$withDatabaseDo$1.apply(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:157)\n\tat com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:237)\n\tat com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator$lzycompute(MongoRDD.scala:221)\n\tat com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator(MongoRDD.scala:221)\n\tat com.mongodb.spark.sql.MongoInferSchema$.apply(MongoInferSchema.scala:68)\n\tat com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:97)\n\tat com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:318)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:167)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bc1cee2ffef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m          \u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mongo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m          \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.mongodb.input.uri\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mongodb://165.22.199.122/processed.internal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m          \u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m          \u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o86.load.\n: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=165.22.199.122:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.SocketTimeoutException: connect timed out}}]\n\tat com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:182)\n\tat com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)\n\tat com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:136)\n\tat com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:94)\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:249)\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:172)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:184)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:153)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:148)\n\tat com.mongodb.spark.MongoConnector$$anonfun$1.apply(MongoConnector.scala:237)\n\tat com.mongodb.spark.MongoConnector$$anonfun$1.apply(MongoConnector.scala:237)\n\tat com.mongodb.spark.MongoConnector$$anonfun$withDatabaseDo$1.apply(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector$$anonfun$withDatabaseDo$1.apply(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:157)\n\tat com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:237)\n\tat com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator$lzycompute(MongoRDD.scala:221)\n\tat com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator(MongoRDD.scala:221)\n\tat com.mongodb.spark.sql.MongoInferSchema$.apply(MongoInferSchema.scala:68)\n\tat com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:97)\n\tat com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:318)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:167)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "df = (spark\n",
    "         .read\n",
    "         .format(\"mongo\")\n",
    "         .option(\"spark.mongodb.input.uri\", \"mongodb://165.22.199.122/processed.internal\")\n",
    "         .load()\n",
    "         .drop('_id')\n",
    "         .orderBy('window.end'))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a transformer to calculate the price difference and generate the y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDiffTransformer(Transformer):\n",
    "    \"\"\"\n",
    "    Custorm tranformer that calculates the price difference since the last time period\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(PriceDiffTransformer, self).__init__()\n",
    "        \n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        # Define the window function\n",
    "        window = Window.partitionBy().orderBy('timestamp')\n",
    "\n",
    "        # Create a price lag of 1 window\n",
    "        df = df.withColumn('prev_price', F.lag(df.price).over(window))\n",
    "\n",
    "        # Calculate the price difference\n",
    "        df = df.withColumn('price_diff', df.price - df.prev_price)\n",
    "        \n",
    "        # Y label\n",
    "        df = df.withColumn('label', F.lag(df.price_diff, -1).over(window))\n",
    "\n",
    "        # Drop the previous price column\n",
    "        df = df.drop('prev_price', 'window')\n",
    "        \n",
    "        # Drop all nan values (first price)\n",
    "        df = df.na.drop()\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_diff_transformer = PriceDiffTransformer()\n",
    "df_price_diff = price_diff_transformer.transform(df)\n",
    "df_price_diff.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a transformer to bring all the features to one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeTransformer(Transformer):\n",
    "    \"\"\"\n",
    "    A custom Transformer which transforms all values to timeseries. This is needed to input it into\n",
    "    the neural network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TimeTransformer, self).__init__()\n",
    "\n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \n",
    "        # Create the timeseries. Window 24 minutes and collect the list of variables needed\n",
    "        df_window = (df\n",
    "             .groupBy(F.window(df.timestamp, '24 minutes', '2 minutes'))\n",
    "             .agg(\n",
    "                 F.collect_list('price_diff'), \n",
    "                 F.collect_list('sentiment'), \n",
    "                 F.collect_list('n_tweets'),\n",
    "                 F.max('timestamp').alias('timestamp'),\n",
    "                 F.last('label').alias('label')))\n",
    "\n",
    "        # Concatenate all array columns\n",
    "        df_features = df_window.withColumn('features', \n",
    "                    F.concat(\n",
    "                        F.col('collect_list(price_diff)'), \n",
    "                        F.col('collect_list(sentiment)'),\n",
    "                        F.col('collect_list(n_tweets)')))\n",
    "\n",
    "        # Make sure all the values are there\n",
    "        df_features = df_features.where(F.size(F.col('features')) == 36)\n",
    "        \n",
    "        # Dropped the left over array columns\n",
    "        df_features = df_features.drop(\n",
    "            'window', \n",
    "            'collect_list(price_diff)', \n",
    "            'collect_list(sentiment)', \n",
    "            'collect_list(n_tweets)')\n",
    "\n",
    "        # Parse the features as vector instead of array (length need to be consistent)\n",
    "        list_to_vector_udf = F.udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "        df_features = df_features.select(\n",
    "            df_features[\"label\"], \n",
    "            df_features[\"timestamp\"], \n",
    "            list_to_vector_udf(df_features[\"features\"]).alias(\"features\"))\n",
    "\n",
    "        return df_features.orderBy('timestamp').drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "|  4.167999999997846|[-3.0224999999991...|\n",
      "|  4.188000000001921|[-0.7291666666678...|\n",
      "|  5.620999999999185|[-1.8633333333345...|\n",
      "|  6.601999999998952|[3.37399999999979...|\n",
      "| 0.5560000000004948|[2.28800000000046...|\n",
      "| -2.252999999998792|[2.50200000000040...|\n",
      "|-2.2850000000016735|[2.92100000000027...|\n",
      "|-2.3690000000005966|[3.37399999999979...|\n",
      "|  2.293999999999869|[-1.9300000000002...|\n",
      "| 3.3920000000016444|[-3.2860000000000...|\n",
      "| 1.8870000000006257|[-3.9680000000007...|\n",
      "| 2.8659999999999854|[0.39300000000184...|\n",
      "| 3.3369999999995343|[4.16799999999784...|\n",
      "| -1.728000000000975|[4.18800000000192...|\n",
      "| -1.617999999998574|[5.62099999999918...|\n",
      "|-2.0610000000015134|[6.60199999999895...|\n",
      "|-2.6849999999994907|[0.55600000000049...|\n",
      "| -3.996999999999389|[-2.2529999999987...|\n",
      "| -4.450999999999112|[-2.2850000000016...|\n",
      "| -4.472000000001572|[-2.3690000000005...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_transformer = TimeTransformer()\n",
    "df_time = time_transformer.transform(df_price_diff)\n",
    "df_time.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of the pipeline without the estimator in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1408.showString.\n: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nObjectHashAggregate(keys=[window#204178], functions=[collect_list(price_diff#204130, 0, 0), collect_list(sentiment#96106, 0, 0), collect_list(n_tweets#96104L, 0, 0), max(timestamp#96107), last(label#204138, false)], output=[collect_list(price_diff)#204175, collect_list(sentiment)#204176, collect_list(n_tweets)#204177, timestamp#204172, label#204174])\n+- Exchange hashpartitioning(window#204178, 200)\n   +- ObjectHashAggregate(keys=[window#204178], functions=[partial_collect_list(price_diff#204130, 0, 0), partial_collect_list(sentiment#96106, 0, 0), partial_collect_list(n_tweets#96104L, 0, 0), partial_max(timestamp#96107), partial_last(label#204138, false)], output=[window#204178, buf#204234, buf#204235, buf#204236, max#204237, last#204238, valueSet#204239])\n      +- *(5) Filter (((isnotnull(timestamp#96107) && isnotnull(window#204178)) && (timestamp#96107 >= window#204178.start)) && (timestamp#96107 < window#204178.end))\n         +- *(5) Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138)], [window#204178, n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n            +- *(5) Project [n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n               +- *(5) Filter AtLeastNNulls(n, n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,price_diff#204130,label#204138)\n                  +- Window [lag(price_diff#204130, -1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS label#204138], [timestamp#96107 ASC NULLS FIRST]\n                     +- *(4) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107, (price#96105 - prev_price#204123) AS price_diff#204130]\n                        +- Window [lag(price#96105, 1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS prev_price#204123], [timestamp#96107 ASC NULLS FIRST]\n                           +- *(3) Sort [timestamp#96107 ASC NULLS FIRST], false, 0\n                              +- Exchange SinglePartition\n                                 +- *(2) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107]\n                                    +- *(2) Sort [window#96108.end ASC NULLS FIRST], true, 0\n                                       +- Exchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n                                          +- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.doExecute(ObjectHashAggregateExec.scala:100)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.doExecute(EvalPythonExec.scala:87)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange hashpartitioning(window#204178, 200)\n+- ObjectHashAggregate(keys=[window#204178], functions=[partial_collect_list(price_diff#204130, 0, 0), partial_collect_list(sentiment#96106, 0, 0), partial_collect_list(n_tweets#96104L, 0, 0), partial_max(timestamp#96107), partial_last(label#204138, false)], output=[window#204178, buf#204234, buf#204235, buf#204236, max#204237, last#204238, valueSet#204239])\n   +- *(5) Filter (((isnotnull(timestamp#96107) && isnotnull(window#204178)) && (timestamp#96107 >= window#204178.start)) && (timestamp#96107 < window#204178.end))\n      +- *(5) Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138)], [window#204178, n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n         +- *(5) Project [n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n            +- *(5) Filter AtLeastNNulls(n, n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,price_diff#204130,label#204138)\n               +- Window [lag(price_diff#204130, -1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS label#204138], [timestamp#96107 ASC NULLS FIRST]\n                  +- *(4) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107, (price#96105 - prev_price#204123) AS price_diff#204130]\n                     +- Window [lag(price#96105, 1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS prev_price#204123], [timestamp#96107 ASC NULLS FIRST]\n                        +- *(3) Sort [timestamp#96107 ASC NULLS FIRST], false, 0\n                           +- Exchange SinglePartition\n                              +- *(2) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107]\n                                 +- *(2) Sort [window#96108.end ASC NULLS FIRST], true, 0\n                                    +- Exchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n                                       +- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1.apply(ObjectHashAggregateExec.scala:105)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1.apply(ObjectHashAggregateExec.scala:100)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 56 more\nCaused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nObjectHashAggregate(keys=[window#204178], functions=[partial_collect_list(price_diff#204130, 0, 0), partial_collect_list(sentiment#96106, 0, 0), partial_collect_list(n_tweets#96104L, 0, 0), partial_max(timestamp#96107), partial_last(label#204138, false)], output=[window#204178, buf#204234, buf#204235, buf#204236, max#204237, last#204238, valueSet#204239])\n+- *(5) Filter (((isnotnull(timestamp#96107) && isnotnull(window#204178)) && (timestamp#96107 >= window#204178.start)) && (timestamp#96107 < window#204178.end))\n   +- *(5) Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138)], [window#204178, n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n      +- *(5) Project [n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n         +- *(5) Filter AtLeastNNulls(n, n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,price_diff#204130,label#204138)\n            +- Window [lag(price_diff#204130, -1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS label#204138], [timestamp#96107 ASC NULLS FIRST]\n               +- *(4) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107, (price#96105 - prev_price#204123) AS price_diff#204130]\n                  +- Window [lag(price#96105, 1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS prev_price#204123], [timestamp#96107 ASC NULLS FIRST]\n                     +- *(3) Sort [timestamp#96107 ASC NULLS FIRST], false, 0\n                        +- Exchange SinglePartition\n                           +- *(2) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107]\n                              +- *(2) Sort [window#96108.end ASC NULLS FIRST], true, 0\n                                 +- Exchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n                                    +- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.doExecute(ObjectHashAggregateExec.scala:100)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 66 more\nCaused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange SinglePartition\n+- *(2) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107]\n   +- *(2) Sort [window#96108.end ASC NULLS FIRST], true, 0\n      +- Exchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n         +- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.window.WindowExec.doExecute(WindowExec.scala:302)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.window.WindowExec.doExecute(WindowExec.scala:302)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ExpandExec.inputRDDs(ExpandExec.scala:90)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1.apply(ObjectHashAggregateExec.scala:105)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1.apply(ObjectHashAggregateExec.scala:100)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 77 more\nCaused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n+- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 131 more\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=165.22.199.122:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message}, caused by {java.net.SocketTimeoutException: Read timed out}}]\n\tat com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:182)\n\tat com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)\n\tat com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:136)\n\tat com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:94)\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:249)\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:172)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:184)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:153)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:148)\n\tat com.mongodb.spark.MongoConnector$$anonfun$1.apply(MongoConnector.scala:237)\n\tat com.mongodb.spark.MongoConnector$$anonfun$1.apply(MongoConnector.scala:237)\n\tat com.mongodb.spark.MongoConnector$$anonfun$withDatabaseDo$1.apply(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector$$anonfun$withDatabaseDo$1.apply(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:157)\n\tat com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:237)\n\tat com.mongodb.spark.rdd.partitioner.DefaultMongoPartitioner.partitions(DefaultMongoPartitioner.scala:33)\n\tat com.mongodb.spark.rdd.MongoRDD.getPartitions(MongoRDD.scala:135)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:170)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 152 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b1ad410e5b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtransform_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprice_diff_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_transformer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1408.showString.\n: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nObjectHashAggregate(keys=[window#204178], functions=[collect_list(price_diff#204130, 0, 0), collect_list(sentiment#96106, 0, 0), collect_list(n_tweets#96104L, 0, 0), max(timestamp#96107), last(label#204138, false)], output=[collect_list(price_diff)#204175, collect_list(sentiment)#204176, collect_list(n_tweets)#204177, timestamp#204172, label#204174])\n+- Exchange hashpartitioning(window#204178, 200)\n   +- ObjectHashAggregate(keys=[window#204178], functions=[partial_collect_list(price_diff#204130, 0, 0), partial_collect_list(sentiment#96106, 0, 0), partial_collect_list(n_tweets#96104L, 0, 0), partial_max(timestamp#96107), partial_last(label#204138, false)], output=[window#204178, buf#204234, buf#204235, buf#204236, max#204237, last#204238, valueSet#204239])\n      +- *(5) Filter (((isnotnull(timestamp#96107) && isnotnull(window#204178)) && (timestamp#96107 >= window#204178.start)) && (timestamp#96107 < window#204178.end))\n         +- *(5) Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138)], [window#204178, n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n            +- *(5) Project [n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n               +- *(5) Filter AtLeastNNulls(n, n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,price_diff#204130,label#204138)\n                  +- Window [lag(price_diff#204130, -1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS label#204138], [timestamp#96107 ASC NULLS FIRST]\n                     +- *(4) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107, (price#96105 - prev_price#204123) AS price_diff#204130]\n                        +- Window [lag(price#96105, 1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS prev_price#204123], [timestamp#96107 ASC NULLS FIRST]\n                           +- *(3) Sort [timestamp#96107 ASC NULLS FIRST], false, 0\n                              +- Exchange SinglePartition\n                                 +- *(2) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107]\n                                    +- *(2) Sort [window#96108.end ASC NULLS FIRST], true, 0\n                                       +- Exchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n                                          +- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.doExecute(ObjectHashAggregateExec.scala:100)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.python.EvalPythonExec.doExecute(EvalPythonExec.scala:87)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange hashpartitioning(window#204178, 200)\n+- ObjectHashAggregate(keys=[window#204178], functions=[partial_collect_list(price_diff#204130, 0, 0), partial_collect_list(sentiment#96106, 0, 0), partial_collect_list(n_tweets#96104L, 0, 0), partial_max(timestamp#96107), partial_last(label#204138, false)], output=[window#204178, buf#204234, buf#204235, buf#204236, max#204237, last#204238, valueSet#204239])\n   +- *(5) Filter (((isnotnull(timestamp#96107) && isnotnull(window#204178)) && (timestamp#96107 >= window#204178.start)) && (timestamp#96107 < window#204178.end))\n      +- *(5) Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138)], [window#204178, n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n         +- *(5) Project [n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n            +- *(5) Filter AtLeastNNulls(n, n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,price_diff#204130,label#204138)\n               +- Window [lag(price_diff#204130, -1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS label#204138], [timestamp#96107 ASC NULLS FIRST]\n                  +- *(4) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107, (price#96105 - prev_price#204123) AS price_diff#204130]\n                     +- Window [lag(price#96105, 1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS prev_price#204123], [timestamp#96107 ASC NULLS FIRST]\n                        +- *(3) Sort [timestamp#96107 ASC NULLS FIRST], false, 0\n                           +- Exchange SinglePartition\n                              +- *(2) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107]\n                                 +- *(2) Sort [window#96108.end ASC NULLS FIRST], true, 0\n                                    +- Exchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n                                       +- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1.apply(ObjectHashAggregateExec.scala:105)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1.apply(ObjectHashAggregateExec.scala:100)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 56 more\nCaused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nObjectHashAggregate(keys=[window#204178], functions=[partial_collect_list(price_diff#204130, 0, 0), partial_collect_list(sentiment#96106, 0, 0), partial_collect_list(n_tweets#96104L, 0, 0), partial_max(timestamp#96107), partial_last(label#204138, false)], output=[window#204178, buf#204234, buf#204235, buf#204236, max#204237, last#204238, valueSet#204239])\n+- *(5) Filter (((isnotnull(timestamp#96107) && isnotnull(window#204178)) && (timestamp#96107 >= window#204178.start)) && (timestamp#96107 < window#204178.end))\n   +- *(5) Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 0) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 1) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 2) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 3) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 4) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 5) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 6) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 7) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 8) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 9) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 10) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) as double) = (cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) THEN (CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) + 1) ELSE CEIL((cast((precisetimestampconversion(timestamp#96107, TimestampType, LongType) - 0) as double) / 1.2E8)) END + 11) - 12) * 120000000) + 1440000000), LongType, TimestampType)), n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138)], [window#204178, n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n      +- *(5) Project [n_tweets#96104L, sentiment#96106, timestamp#96107, price_diff#204130, label#204138]\n         +- *(5) Filter AtLeastNNulls(n, n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,price_diff#204130,label#204138)\n            +- Window [lag(price_diff#204130, -1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS label#204138], [timestamp#96107 ASC NULLS FIRST]\n               +- *(4) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107, (price#96105 - prev_price#204123) AS price_diff#204130]\n                  +- Window [lag(price#96105, 1, null) windowspecdefinition(timestamp#96107 ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS prev_price#204123], [timestamp#96107 ASC NULLS FIRST]\n                     +- *(3) Sort [timestamp#96107 ASC NULLS FIRST], false, 0\n                        +- Exchange SinglePartition\n                           +- *(2) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107]\n                              +- *(2) Sort [window#96108.end ASC NULLS FIRST], true, 0\n                                 +- Exchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n                                    +- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.doExecute(ObjectHashAggregateExec.scala:100)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 66 more\nCaused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange SinglePartition\n+- *(2) Project [n_tweets#96104L, price#96105, sentiment#96106, timestamp#96107]\n   +- *(2) Sort [window#96108.end ASC NULLS FIRST], true, 0\n      +- Exchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n         +- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.window.WindowExec.doExecute(WindowExec.scala:302)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.window.WindowExec.doExecute(WindowExec.scala:302)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.ExpandExec.inputRDDs(ExpandExec.scala:90)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1.apply(ObjectHashAggregateExec.scala:105)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1.apply(ObjectHashAggregateExec.scala:100)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 77 more\nCaused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:\nExchange rangepartitioning(window#96108.end ASC NULLS FIRST, 200)\n+- *(1) Scan MongoRelation(MongoRDD[2736] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(n_tweets,LongType,true), StructField(price,DoubleType,true), StructField(sentiment,DoubleType,true), StructField(timestamp,TimestampType,true), StructField(window,StructType(StructField(start,TimestampType,true), StructField(end,TimestampType,true)),true)))) [n_tweets#96104L,price#96105,sentiment#96106,timestamp#96107,window#96108] PushedFilters: [], ReadSchema: struct<n_tweets:bigint,price:double,sentiment:double,timestamp:timestamp,window:struct<start:time...\n\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:391)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:627)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 131 more\nCaused by: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=165.22.199.122:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message}, caused by {java.net.SocketTimeoutException: Read timed out}}]\n\tat com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:182)\n\tat com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)\n\tat com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:136)\n\tat com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:94)\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:249)\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:172)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:184)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:153)\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:148)\n\tat com.mongodb.spark.MongoConnector$$anonfun$1.apply(MongoConnector.scala:237)\n\tat com.mongodb.spark.MongoConnector$$anonfun$1.apply(MongoConnector.scala:237)\n\tat com.mongodb.spark.MongoConnector$$anonfun$withDatabaseDo$1.apply(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector$$anonfun$withDatabaseDo$1.apply(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:157)\n\tat com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:174)\n\tat com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:237)\n\tat com.mongodb.spark.rdd.partitioner.DefaultMongoPartitioner.partitions(DefaultMongoPartitioner.scala:33)\n\tat com.mongodb.spark.rdd.MongoRDD.getPartitions(MongoRDD.scala:135)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:251)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:170)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\t... 152 more\n"
     ]
    }
   ],
   "source": [
    "price_diff_transformer = PriceDiffTransformer()\n",
    "time_transformer = TimeTransformer()\n",
    "\n",
    "transform_pipeline = Pipeline(stages=[price_diff_transformer, time_transformer]).fit(df)\n",
    "df_transform = transform_pipeline.transform(df)\n",
    "df_transform.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------------+\n",
      "|              label|            features|         prediction|\n",
      "+-------------------+--------------------+-------------------+\n",
      "|  4.167999999997846|[-3.0224999999991...| 0.2053055007052389|\n",
      "|  4.188000000001921|[-0.7291666666678...|  3.362338944625241|\n",
      "|  5.620999999999185|[-1.8633333333345...| 3.4353698813804976|\n",
      "|  6.601999999998952|[3.37399999999979...|  4.327813524679511|\n",
      "| 0.5560000000004948|[2.28800000000046...|  4.732287874305415|\n",
      "| -2.252999999998792|[2.50200000000040...|-0.0764380375963038|\n",
      "|-2.2850000000016735|[2.92100000000027...|-2.2853606746837314|\n",
      "|-2.3690000000005966|[3.37399999999979...| -2.348738900883713|\n",
      "|  2.293999999999869|[-1.9300000000002...| -2.149795796386036|\n",
      "| 3.3920000000016444|[-3.2860000000000...|  1.794769097891225|\n",
      "| 1.8870000000006257|[-3.9680000000007...| 2.7488014416828888|\n",
      "| 2.8659999999999854|[0.39300000000184...| 1.5426995218545212|\n",
      "| 3.3369999999995343|[4.16799999999784...| 2.0787630518835316|\n",
      "| -1.728000000000975|[4.18800000000192...|  2.217470721663567|\n",
      "| -1.617999999998574|[5.62099999999918...|-1.6565266216450838|\n",
      "|-2.0610000000015134|[6.60199999999895...|-1.5371379143557478|\n",
      "|-2.6849999999994907|[0.55600000000049...|-1.8861584619962732|\n",
      "| -3.996999999999389|[-2.2529999999987...| -2.161691936218637|\n",
      "| -4.450999999999112|[-2.2850000000016...|-2.9788307007600023|\n",
      "| -4.472000000001572|[-2.3690000000005...|  -3.30151308452925|\n",
      "+-------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "price_diff_transformer = PriceDiffTransformer()\n",
    "time_transformer = TimeTransformer()\n",
    "lr_estimator = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[price_diff_transformer, time_transformer, lr_estimator]).fit(df)\n",
    "df_lr = lr_pipeline.transform(df)\n",
    "df_lr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rdd = df_lr.rdd.map(lambda p: (p.prediction, p.label)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4540291933605607"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = RegressionMetrics(pred_rdd)\n",
    "metrics.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elephas prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(36,)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss=root_mean_squared_error)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 64)                2368      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,481\n",
      "Trainable params: 4,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model = build_model()\n",
    "keras_model.load_weights('models/keras_weights.hdf5')\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElephasEstimator_ebae0e9247e9"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.01)\n",
    "opt_conf = optimizers.serialize(adam)\n",
    "\n",
    "# Initialize SparkML Estimator and set all relevant properties\n",
    "estimator = ElephasEstimator()\n",
    "estimator.setFeaturesCol('features')\n",
    "estimator.setLabelCol('label')\n",
    "estimator.set_keras_model_config(keras_model.to_yaml())\n",
    "estimator.set_categorical_labels(False)\n",
    "# estimator.set_nb_classes(nb_classes)\n",
    "estimator.set_num_workers(1)\n",
    "estimator.set_epochs(5) \n",
    "estimator.set_batch_size(128)\n",
    "estimator.set_verbosity(1)\n",
    "estimator.set_validation_split(0.15)\n",
    "estimator.set_optimizer_config(opt_conf)\n",
    "estimator.set_mode('synchronous')\n",
    "estimator.set_loss('mean_squared_error')\n",
    "estimator.set_metrics(['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Pipeline(stages=[price_diff_transformer, time_transformer, estimator]).fit(df)\n",
    "df_pred = model.transform(df)\n",
    "df_pred.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"dd-MM-yyyy HH:mm:ss\"\n",
    "\n",
    "# Create the schema of incoming data\n",
    "twitter_schema = T.StructType([\n",
    "    T.StructField('timestamp', T.TimestampType(), False),\n",
    "    T.StructField('text', T.StringType(), False),\n",
    "    T.StructField('sentiment', T.DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read kafka stream and subscribe to twitter topic\n",
    "twitter_stream = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'twitter')\n",
    "          .load()\n",
    "          .select(F.col(\"key\").cast(\"string\"), \\\n",
    "                  F.from_json(F.col(\"value\").cast(\"string\"), twitter_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create streaming moving windows\n",
    "twitter_aggregation = (twitter_stream\n",
    "                     .select('value.*')\n",
    "                     .withWatermark('timestamp', '5 seconds')\n",
    "                     .groupBy(window('timestamp', '30 seconds', '5 seconds'))\n",
    "                     .agg(avg('sentiment').alias('sentiment'), count('timestamp').alias('n_tweets'))).select(F.col('window.end').alias('timestamp'), F.col('sentiment'), F.col('n_tweets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_agg_stream = (twitter_aggregation\n",
    "    .writeStream\n",
    "    .outputMode(\"append\")\n",
    "    .format(\"console\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_agg_stream.stop()\n",
    "crypto_agg_stream.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f4a4f966cc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the timestamp as key\n",
    "twitter_aggregation = twitter_aggregation.withColumn('key', F.col('timestamp'))\n",
    "\n",
    "# Send the data to kafka\n",
    "(twitter_aggregation\n",
    "    .selectExpr(\"CAST(key AS STRING) AS key\", \"to_json(struct(*)) AS value\")\n",
    "    .writeStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\n",
    "    .option(\"topic\", \"twitter-agg\")\n",
    "    .option(\"checkpointLocation\", \"checkpoints/twitter-agg\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crypto stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"dd-MM-yyyy HH:mm:ss\"\n",
    "\n",
    "# Create the schema of incoming data\n",
    "crypto_schema = T.StructType([\n",
    "    T.StructField('timestamp', T.TimestampType(), False),\n",
    "    T.StructField('price', T.DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read kafka stream and subscribe to crypto topic\n",
    "crypto_stream = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'crypto')\n",
    "          .load()\n",
    "          .select(F.col(\"key\").cast(\"string\"), \\\n",
    "                  F.from_json(F.col(\"value\").cast(\"string\"), crypto_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create streaming moving windows\n",
    "crypto_aggregation = (crypto_stream\n",
    "                     .select('value.*')\n",
    "                     .withWatermark('timestamp', '5 seconds')\n",
    "                     .groupBy(window('timestamp', '30 seconds', '5 seconds'))\n",
    "                     .agg(avg('price').alias('price'))).select(F.col('window.end').alias('timestamp'), F.col('price'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f4a4f966320>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the timestamp as key\n",
    "crypto_aggregation = crypto_aggregation.withColumn('key', F.col('timestamp'))\n",
    "\n",
    "# Send the data to kafka\n",
    "(crypto_aggregation\n",
    "    .selectExpr(\"CAST(key AS STRING) AS key\", \"to_json(struct(*)) AS value\")\n",
    "    .writeStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\")\n",
    "    .option(\"topic\", \"crypto-agg\")\n",
    "    .option(\"checkpointLocation\", \"checkpoints/crypto-agg\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the crypto aggregation stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the schema of incoming aggregated crypto data\n",
    "crypto_agg_schema = T.StructType([\n",
    "    T.StructField('timestamp', T.TimestampType(), False),\n",
    "    T.StructField('price', T.DoubleType(), False)\n",
    "])\n",
    "\n",
    "# Read the crypto aggregation stream\n",
    "crypto_agg_stream = ((spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'crypto-agg')\n",
    "          .load()\n",
    "          .select(\n",
    "              F.col(\"key\").cast(\"string\"), \n",
    "              F.from_json(F.col(\"value\").cast(\"string\"), crypto_agg_schema).alias(\"value\")))\n",
    "                     .select('value.*'))\n",
    "\n",
    "crypto_agg_stream.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the twitter aggregation stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      " |-- n_tweets: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the schema of incoming aggregated crypto data\n",
    "twitter_agg_schema = T.StructType([\n",
    "    T.StructField('timestamp', T.TimestampType(), False),\n",
    "    T.StructField('sentiment', T.DoubleType(), False),\n",
    "    T.StructField('n_tweets', T.IntegerType(), False)\n",
    "])\n",
    "\n",
    "# Read the twitter aggregation stream\n",
    "twitter_agg_stream = ((spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'twitter-agg')\n",
    "          .load()\n",
    "          .select(\n",
    "              F.col(\"key\").cast(\"string\"), \n",
    "              F.from_json(F.col(\"value\").cast(\"string\"), twitter_agg_schema).alias(\"value\")))\n",
    "                     .select('value.*'))\n",
    "\n",
    "twitter_agg_stream.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the two streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_stream = crypto_agg_stream.join(twitter_agg_stream, 'timestamp').withWatermark('timestamp', '10 seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_reader = (merged_stream\n",
    "    .writeStream\n",
    "    .format(\"console\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_reader.stop()\n",
    "stream_reader.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Queries with streaming sources must be executed with writeStream.start();;\\nkafka'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1213.showString.\n: org.apache.spark.sql.AnalysisException: Queries with streaming sources must be executed with writeStream.start();;\nkafka\n\tat org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$.org$apache$spark$sql$catalyst$analysis$UnsupportedOperationChecker$$throwError(UnsupportedOperationChecker.scala:389)\n\tat org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$$anonfun$checkForBatch$1.apply(UnsupportedOperationChecker.scala:38)\n\tat org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$$anonfun$checkForBatch$1.apply(UnsupportedOperationChecker.scala:36)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:126)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.UnsupportedOperationChecker$.checkForBatch(UnsupportedOperationChecker.scala:36)\n\tat org.apache.spark.sql.execution.QueryExecution.assertSupported(QueryExecution.scala:51)\n\tat org.apache.spark.sql.execution.QueryExecution.withCachedData$lzycompute(QueryExecution.scala:62)\n\tat org.apache.spark.sql.execution.QueryExecution.withCachedData(QueryExecution.scala:60)\n\tat org.apache.spark.sql.execution.QueryExecution.optimizedPlan$lzycompute(QueryExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution.optimizedPlan(QueryExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:72)\n\tat org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:68)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:77)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:77)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3365)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-5ae5ef12d5ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprice_diff_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPriceDiffTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_price_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprice_diff_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_price_diff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \"\"\"\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Queries with streaming sources must be executed with writeStream.start();;\\nkafka'"
     ]
    }
   ],
   "source": [
    "price_diff_transformer = PriceDiffTransformer()\n",
    "df_price_diff = price_diff_transformer.transform(merged_stream)\n",
    "df_price_diff.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transform = transform_pipeline.transform(merged_stream)\n",
    "df_transform.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
