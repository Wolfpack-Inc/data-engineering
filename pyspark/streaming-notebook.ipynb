{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, avg, count\n",
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField, IntegerType, TimestampType, DoubleType\n",
    "from pyspark.sql.functions import from_json, col, to_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = SparkSession.builder.appName(\"Twitter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to twitter topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"E MMM dd HH:mm:ss +0000 yyyy\"\n",
    "\n",
    "# Create the schema of incoming data\n",
    "twitter_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('text', StringType(), False),\n",
    "    StructField('sentiment', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read kafka stream and subscribe to twitter topic\n",
    "twitter_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka-1:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'twitter')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), twitter_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "twitter_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter = twitter_df.select('value.*')\n",
    "twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_stream = (twitter\n",
    "         .writeStream\n",
    "         .queryName(\"twitter\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---------+\n",
      "|          timestamp|                text|sentiment|\n",
      "+-------------------+--------------------+---------+\n",
      "|2019-11-01 11:18:30|Free 300 GH Cloud...|   0.5106|\n",
      "|2019-11-01 11:18:31|@Crystamped Crypt...|   0.4404|\n",
      "|2019-11-01 11:18:31|https://t.co/ip7K...|      0.0|\n",
      "|2019-11-01 11:18:32|RT @santimentfeed...|      0.0|\n",
      "|2019-11-01 11:18:39|Bakkt: Bitcoin Fu...|      0.0|\n",
      "|2019-11-01 11:18:39|Donâ€™t do a @MadBi...|      0.0|\n",
      "|2019-11-01 11:18:43|RT @crypfo1: http...|      0.0|\n",
      "|2019-11-01 11:18:44|RT @stacyherbert:...|      0.0|\n",
      "|2019-11-01 11:18:47|RT @DACX_io: ðŸ’« T...|      0.0|\n",
      "|2019-11-01 11:18:48|RT @xcardbymobilu...|   0.6114|\n",
      "|2019-11-01 11:18:49|Bitcoin, last mon...|   0.5267|\n",
      "|2019-11-01 11:18:52|    bitcoin, stocks,|      0.0|\n",
      "|2019-11-01 11:18:54|RT @Rhythmtrader:...|   0.5267|\n",
      "|2019-11-01 11:18:54|Bitcoinâ€™s Defense...|   0.4939|\n",
      "|2019-11-01 11:18:55|RT @skwp: If you'...|     0.34|\n",
      "|2019-11-01 11:18:58|RT @KarlTurner5: ...|     0.34|\n",
      "|2019-11-01 11:18:58|RT @GarlamWon: @B...|   0.4404|\n",
      "|2019-11-01 11:19:01|RT @eToro: Happy ...|   0.6114|\n",
      "|2019-11-01 11:19:04|RT @Rhythmtrader:...|   0.5267|\n",
      "|2019-11-01 11:19:04|RT @Rhythmtrader:...|   0.5267|\n",
      "+-------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from twitter\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to crypto topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema of incoming data\n",
    "crypto_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('price', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"dd-mm-yyyy HH:mm:ss\"\n",
    "\n",
    "# Read kafka stream and subscribe to crypto topic\n",
    "crypto_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka-1:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'crypto')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), crypto_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "crypto_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto = crypto_df.select('value.*')\n",
    "crypto.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df_stream = (crypto\n",
    "         .writeStream\n",
    "         .queryName(\"crypto\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|timestamp|price|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from crypto\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_aggregation = (twitter\n",
    "                     .groupBy(window(twitter.timestamp, '30 seconds'))\n",
    "                     .agg(avg('sentiment').alias('sentiment'), count('timestamp').alias('n_tweets')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweet_agg_stream = (tweet_aggregation\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .queryName(\"tweets_aggs\")\n",
    "    .format(\"memory\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      " |-- n_tweets: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from tweets_aggs\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------+\n",
      "|start|sentiment|n_tweets|\n",
      "+-----+---------+--------+\n",
      "+-----+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df = spark.sql(\"select window.start, sentiment, n_tweets from tweets_aggs\")\n",
    "tweet_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_agg_stream.stop()\n",
    "tweet_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crypto aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[start: timestamp, price: double]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_aggregation = (crypto\n",
    "                     .groupBy(window(crypto.timestamp, '30 seconds'))\n",
    "                     .agg(avg('price').alias('price'))\n",
    "                     .select(['window.start', 'price']))\n",
    "\n",
    "crypto_aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crypto_agg_stream = (crypto_aggregation\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .queryName(\"crypto_agg\")\n",
    "    .format(\"memory\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|start              |price  |\n",
      "+-------------------+-------+\n",
      "|2019-01-01 11:20:00|8324.27|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df = spark.sql(\"select start, price from crypto_agg\")\n",
    "crypto_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_agg_stream.stop()\n",
    "crypto_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the two streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+\n",
      "|              start|          sentiment|n_tweets|\n",
      "+-------------------+-------------------+--------+\n",
      "|2019-11-01 11:21:00| 0.1809111111111111|      18|\n",
      "|2019-11-01 11:20:00|        0.160221875|      32|\n",
      "|2019-11-01 11:19:30|0.09883636363636362|      11|\n",
      "|2019-11-01 11:22:30|0.22011666666666665|      30|\n",
      "|2019-11-01 11:23:00|0.10823333333333333|       3|\n",
      "|2019-11-01 11:21:30|0.15878421052631578|      19|\n",
      "|2019-11-01 11:22:00|0.21068846153846155|      26|\n",
      "|2019-11-01 11:20:30| 0.3449722222222222|      18|\n",
      "+-------------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|              start|            price|\n",
      "+-------------------+-----------------+\n",
      "|2019-01-01 11:21:30|8319.603333333334|\n",
      "|2019-01-01 11:21:00|8323.869999999999|\n",
      "|2019-01-01 11:20:00|         8325.196|\n",
      "|2019-01-01 11:20:30|8326.328333333333|\n",
      "|2019-01-01 11:22:30|         8305.995|\n",
      "|2019-01-01 11:23:00|8299.199999999999|\n",
      "|2019-01-01 11:22:00|8311.749999999998|\n",
      "+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------+-----+\n",
      "|start|sentiment|n_tweets|price|\n",
      "+-----+---------+--------+-----+\n",
      "+-----+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.join(crypto_agg_df, 'start').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
