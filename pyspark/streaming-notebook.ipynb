{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, avg, count\n",
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField, IntegerType, TimestampType, DoubleType\n",
    "from pyspark.sql.functions import from_json, col, to_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = SparkSession.builder.appName(\"Twitter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to twitter topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"dd-MM-yyyy HH:mm:ss\"\n",
    "\n",
    "# Create the schema of incoming data\n",
    "twitter_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('text', StringType(), False),\n",
    "    StructField('sentiment', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read kafka stream and subscribe to twitter topic\n",
    "twitter_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'twitter')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), twitter_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "twitter_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter = twitter_df.select('value.*')\n",
    "twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_stream = (twitter\n",
    "         .writeStream\n",
    "         .queryName(\"twitter\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---------+\n",
      "|          timestamp|                text|sentiment|\n",
      "+-------------------+--------------------+---------+\n",
      "|2019-11-14 21:53:44|If only the RDD i...|      0.0|\n",
      "|2019-11-14 21:53:45|RT @LosingSergej:...|      0.0|\n",
      "|2019-11-14 21:53:45|RT @extstock: Rec...|   0.5562|\n",
      "|2019-11-14 21:53:46|Thu Nov 14 22:52:...|   0.2732|\n",
      "|2019-11-14 21:53:46|Aye! Getting this...|   0.9575|\n",
      "|2019-11-14 21:53:46|@stevekinslow I c...|   0.6798|\n",
      "|2019-11-14 21:53:47|Sales Representat...|      0.0|\n",
      "|2019-11-14 21:53:50|RT @qhfofficial: ...|      0.0|\n",
      "|2019-11-14 21:53:53|WikiLeaks has rec...|     0.34|\n",
      "|2019-11-14 21:53:57|RT @HamEggsnSam: ...|   0.4939|\n",
      "+-------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from twitter\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to crypto topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema of incoming data\n",
    "crypto_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('price', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"dd-MM-yyyy HH:mm:ss\"\n",
    "\n",
    "# Read kafka stream and subscribe to crypto topic\n",
    "crypto_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'crypto')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), crypto_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "crypto_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto = crypto_df.select('value.*')\n",
    "crypto.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df_stream = (crypto\n",
    "         .writeStream\n",
    "         .queryName(\"crypto\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|          timestamp|  price|\n",
      "+-------------------+-------+\n",
      "|2019-11-14 21:54:14|7857.57|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from crypto\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_aggregation = (twitter\n",
    "                     .withWatermark('timestamp', '1 minute')\n",
    "                     .groupBy(window('timestamp', '30 seconds', '5 seconds'))\n",
    "                     .agg(avg('sentiment').alias('sentiment'), count('timestamp').alias('n_tweets')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_agg_stream = (tweet_aggregation\n",
    "    .writeStream\n",
    "    .outputMode('append')\n",
    "    .queryName('tweets_aggs')\n",
    "    .format('memory')\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = true)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      " |-- n_tweets: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from tweets_aggs').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------+\n",
      "|start|sentiment|n_tweets|\n",
      "+-----+---------+--------+\n",
      "+-----+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df = spark.sql('select window.start, sentiment, n_tweets from tweets_aggs')\n",
    "tweet_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_agg_stream.stop()\n",
    "tweet_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crypto aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[start: timestamp, price: double, end: timestamp]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_aggregation = (crypto\n",
    "                     .withWatermark('timestamp', '2 seconds')\n",
    "                     .groupBy(window('timestamp', '30 seconds', '5 seconds'))\n",
    "                     .agg(avg('price').alias('price'))\n",
    "                     .select(['window.start', 'price', 'window.end']))\n",
    "\n",
    "crypto_aggregation\n",
    "\n",
    "# words = ...  # streaming DataFrame of schema { timestamp: Timestamp, word: String }\n",
    "\n",
    "# # Group the data by window and word and compute the count of each group\n",
    "# windowedCounts = words.groupBy(\n",
    "#     window(words.timestamp, \"10 minutes\", \"5 minutes\"),\n",
    "#     words.word\n",
    "# ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crypto_agg_stream = (crypto_aggregation\n",
    "    .writeStream\n",
    "    .outputMode('complete')\n",
    "    .queryName('crypto_agg')\n",
    "    .format('memory')\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+\n",
      "|start              |end                |price            |\n",
      "+-------------------+-------------------+-----------------+\n",
      "|2019-11-14 21:59:50|2019-11-14 22:00:20|7857.868333333333|\n",
      "|2019-11-14 21:59:30|2019-11-14 22:00:00|7857.518333333333|\n",
      "|2019-11-14 22:00:20|2019-11-14 22:00:50|7859.1625        |\n",
      "|2019-11-14 21:59:35|2019-11-14 22:00:05|7857.535         |\n",
      "|2019-11-14 22:00:25|2019-11-14 22:00:55|7859.170000000001|\n",
      "|2019-11-14 21:59:10|2019-11-14 21:59:40|7857.596666666667|\n",
      "|2019-11-14 21:59:55|2019-11-14 22:00:25|7858.143333333333|\n",
      "|2019-11-14 21:59:00|2019-11-14 21:59:30|7857.65          |\n",
      "|2019-11-14 22:00:10|2019-11-14 22:00:40|7858.895         |\n",
      "|2019-11-14 21:59:25|2019-11-14 21:59:55|7857.543333333334|\n",
      "|2019-11-14 22:00:35|2019-11-14 22:01:05|7859.17          |\n",
      "|2019-11-14 22:00:05|2019-11-14 22:00:35|7858.658333333333|\n",
      "|2019-11-14 21:59:40|2019-11-14 22:00:10|7857.578333333334|\n",
      "|2019-11-14 21:59:45|2019-11-14 22:00:15|7857.610000000001|\n",
      "|2019-11-14 21:59:05|2019-11-14 21:59:35|7857.65          |\n",
      "|2019-11-14 22:00:30|2019-11-14 22:01:00|7859.17          |\n",
      "|2019-11-14 21:59:15|2019-11-14 21:59:45|7857.57          |\n",
      "|2019-11-14 22:00:15|2019-11-14 22:00:45|7859.138000000001|\n",
      "|2019-11-14 22:00:00|2019-11-14 22:00:30|7858.421666666666|\n",
      "|2019-11-14 21:59:20|2019-11-14 21:59:50|7857.554000000001|\n",
      "+-------------------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df = spark.sql('select start,end, price from crypto_agg')\n",
    "crypto_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Terminated with exception: Job 187 cancelled part of cancelled job group 64faa655-b488-402b-856c-18c622a2ec91',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_agg_stream.stop()\n",
    "crypto_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the two streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+\n",
      "|              start|          sentiment|n_tweets|\n",
      "+-------------------+-------------------+--------+\n",
      "|2019-11-14 21:19:35|0.16271666666666665|       6|\n",
      "|2019-11-14 21:19:40| 0.2368888888888889|       9|\n",
      "|2019-11-14 21:19:45|0.14646666666666666|      12|\n",
      "|2019-11-14 21:19:50|          0.1613125|      16|\n",
      "|2019-11-14 21:19:55|0.15598695652173913|      23|\n",
      "|2019-11-14 21:20:00|0.19555185185185187|      27|\n",
      "|2019-11-14 21:20:05|            0.20652|      25|\n",
      "|2019-11-14 21:20:10|0.23004285714285716|      28|\n",
      "|2019-11-14 21:20:15|           0.272624|      25|\n",
      "|2019-11-14 21:20:25| 0.3045962962962963|      27|\n",
      "|2019-11-14 21:20:20|0.24680357142857146|      28|\n",
      "|2019-11-14 21:20:30| 0.2979185185185185|      27|\n",
      "+-------------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|start|price|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+------------------+\n",
      "|              start|          sentiment|n_tweets|             price|\n",
      "+-------------------+-------------------+--------+------------------+\n",
      "|2019-11-14 20:04:40|0.25397142857142857|       7|7850.0025000000005|\n",
      "|2019-11-14 20:03:45|0.20998965517241377|      29| 7848.673333333333|\n",
      "|2019-11-14 20:03:50| 0.1462103448275862|      29| 7848.803333333333|\n",
      "|2019-11-14 20:04:10|0.19134285714285718|      28|          7848.965|\n",
      "|2019-11-14 20:04:35| 0.3238230769230769|      13|          7849.938|\n",
      "|2019-11-14 20:04:05|             0.1619|      27|          7848.845|\n",
      "|2019-11-14 20:04:45|0.44444999999999996|       4| 7850.110000000001|\n",
      "|2019-11-14 20:04:50|0.44914999999999994|       2|           7850.35|\n",
      "|2019-11-14 20:03:15| 0.2464421052631579|      19|           7847.27|\n",
      "|2019-11-14 20:03:10|0.27543529411764706|      17|           7847.27|\n",
      "|2019-11-14 20:03:55|0.15807878787878787|      33| 7848.926666666666|\n",
      "|2019-11-14 20:03:30| 0.2130695652173913|      23| 7847.670000000001|\n",
      "|2019-11-14 20:03:40| 0.2160925925925926|      27| 7848.166666666667|\n",
      "|2019-11-14 20:03:20|0.25031363636363635|      22| 7847.266666666667|\n",
      "|2019-11-14 20:03:35|0.20973461538461538|      26| 7847.884999999999|\n",
      "|2019-11-14 20:04:25| 0.2845666666666667|      18|           7849.63|\n",
      "|2019-11-14 20:04:30|             0.3294|      14|          7849.895|\n",
      "|2019-11-14 20:04:00|0.16104687499999998|      32| 7848.724999999999|\n",
      "|2019-11-14 20:03:25| 0.2655818181818182|      22| 7847.275000000001|\n",
      "|2019-11-14 20:04:20|0.24600000000000002|      23|          7849.125|\n",
      "+-------------------+-------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.join(crypto_agg_df, 'start').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
