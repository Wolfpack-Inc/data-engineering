{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, avg, count\n",
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField, IntegerType, TimestampType, DoubleType\n",
    "from pyspark.sql.functions import from_json, col, to_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = SparkSession.builder.appName(\"Twitter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to twitter topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"E MMM dd HH:mm:ss +0000 yyyy\"\n",
    "\n",
    "# Create the schema of incoming data\n",
    "twitter_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('text', StringType(), False),\n",
    "    StructField('sentiment', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read kafka stream and subscribe to twitter topic\n",
    "twitter_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka-1:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'twitter')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), twitter_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "twitter_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter = twitter_df.select('value.*')\n",
    "twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_stream = (twitter\n",
    "         .writeStream\n",
    "         .queryName(\"twitter\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------+\n",
      "|timestamp|text|sentiment|\n",
      "+---------+----+---------+\n",
      "+---------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from twitter\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to crypto topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema of incoming data\n",
    "crypto_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('price', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"dd-MM-yyyy HH:mm:ss\"\n",
    "\n",
    "# Read kafka stream and subscribe to crypto topic\n",
    "crypto_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka-1:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'crypto')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), crypto_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "crypto_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto = crypto_df.select('value.*')\n",
    "crypto.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df_stream = (crypto\n",
    "         .writeStream\n",
    "         .queryName(\"crypto\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|          timestamp|  price|\n",
      "+-------------------+-------+\n",
      "|2019-11-04 10:39:16|8258.99|\n",
      "|2019-11-04 10:39:21|8258.99|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from crypto\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_aggregation = (twitter\n",
    "                     .groupBy(window(twitter.timestamp, '30 seconds'))\n",
    "                     .agg(avg('sentiment').alias('sentiment'), count('timestamp').alias('n_tweets')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweet_agg_stream = (tweet_aggregation\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .queryName(\"tweets_aggs\")\n",
    "    .format(\"memory\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      " |-- n_tweets: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from tweets_aggs\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+--------+\n",
      "|start              |sentiment         |n_tweets|\n",
      "+-------------------+------------------+--------+\n",
      "|2019-11-04 10:39:00|0.39036           |5       |\n",
      "|2019-11-04 10:39:30|0.2583142857142857|7       |\n",
      "+-------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df = spark.sql(\"select window.start, sentiment, n_tweets from tweets_aggs\")\n",
    "tweet_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_agg_stream.stop()\n",
    "tweet_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crypto aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[start: timestamp, price: double]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_aggregation = (crypto\n",
    "                     .groupBy(window(crypto.timestamp, '30 seconds'))\n",
    "                     .agg(avg('price').alias('price'))\n",
    "                     .select(['window.start', 'price']))\n",
    "\n",
    "crypto_aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crypto_agg_stream = (crypto_aggregation\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .queryName(\"crypto_agg\")\n",
    "    .format(\"memory\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|start              |price  |\n",
      "+-------------------+-------+\n",
      "|2019-11-04 10:39:30|8253.86|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df = spark.sql(\"select start, price from crypto_agg\")\n",
    "crypto_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_agg_stream.stop()\n",
    "crypto_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the two streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+\n",
      "|              start|sentiment|n_tweets|\n",
      "+-------------------+---------+--------+\n",
      "|2019-11-04 10:39:00|  0.39036|       5|\n",
      "|2019-11-04 10:39:30| 0.226025|       8|\n",
      "+-------------------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|              start|    price|\n",
      "+-------------------+---------+\n",
      "|2019-11-04 10:39:30|8256.8275|\n",
      "|2019-11-04 10:40:00|  8259.78|\n",
      "+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+---------+\n",
      "|              start|          sentiment|n_tweets|    price|\n",
      "+-------------------+-------------------+--------+---------+\n",
      "|2019-11-04 10:41:30|            0.15418|      15| 8259.895|\n",
      "|2019-11-04 10:40:30|0.16556315789473683|      19|  8260.22|\n",
      "|2019-11-04 10:42:00|0.05328666666666667|      15| 8261.076|\n",
      "|2019-11-04 10:39:30| 0.1889090909090909|      11|8256.8275|\n",
      "|2019-11-04 10:40:00|0.08643684210526316|      19| 8259.896|\n",
      "|2019-11-04 10:41:00|0.20303703703703704|      27| 8259.045|\n",
      "+-------------------+-------------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.join(crypto_agg_df, 'start').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
