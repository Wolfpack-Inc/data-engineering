{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, avg, count\n",
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField, IntegerType, TimestampType, DoubleType\n",
    "from pyspark.sql.functions import from_json, col, to_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = SparkSession.builder.appName(\"Twitter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to twitter topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"E MMM dd HH:mm:ss +0000 yyyy\"\n",
    "\n",
    "# Create the schema of incoming data\n",
    "twitter_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('text', StringType(), False),\n",
    "    StructField('sentiment', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read kafka stream and subscribe to twitter topic\n",
    "twitter_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'twitter')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), twitter_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "twitter_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter = twitter_df.select('value.*')\n",
    "twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_stream = (twitter\n",
    "         .writeStream\n",
    "         .queryName(\"twitter\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------+\n",
      "|timestamp|text|sentiment|\n",
      "+---------+----+---------+\n",
      "+---------+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from twitter\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to crypto topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema of incoming data\n",
    "crypto_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('price', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"dd-MM-yyyy HH:mm:ss\"\n",
    "\n",
    "# Read kafka stream and subscribe to crypto topic\n",
    "crypto_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'crypto')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), crypto_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "crypto_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto = crypto_df.select('value.*')\n",
    "crypto.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df_stream = (crypto\n",
    "         .writeStream\n",
    "         .queryName(\"crypto\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|timestamp|price|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from crypto\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_aggregation = (twitter\n",
    "                     .withWatermark('timestamp', '1 minute')\n",
    "                     .groupBy(window('timestamp', '30 seconds', '5 seconds'))\n",
    "                     .agg(avg('sentiment').alias('sentiment'), count('timestamp').alias('n_tweets')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_agg_stream = (tweet_aggregation\n",
    "    .writeStream\n",
    "    .outputMode('append')\n",
    "    .queryName('tweets_aggs')\n",
    "    .format('memory')\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = true)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      " |-- n_tweets: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from tweets_aggs').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+\n",
      "|start              |sentiment          |n_tweets|\n",
      "+-------------------+-------------------+--------+\n",
      "|2019-11-14 21:19:35|0.16271666666666665|6       |\n",
      "+-------------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df = spark.sql('select window.start, sentiment, n_tweets from tweets_aggs')\n",
    "tweet_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_agg_stream.stop()\n",
    "tweet_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crypto aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[start: timestamp, price: double, end: timestamp]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_aggregation = (crypto\n",
    "                     .withWatermark('timestamp', '1 minute')\n",
    "                     .groupBy(window('timestamp', '30 seconds', '5 seconds'))\n",
    "                     .agg(avg('price').alias('price'))\n",
    "                     .select(['window.start', 'price', 'window.end']))\n",
    "\n",
    "crypto_aggregation\n",
    "\n",
    "# words = ...  # streaming DataFrame of schema { timestamp: Timestamp, word: String }\n",
    "\n",
    "# # Group the data by window and word and compute the count of each group\n",
    "# windowedCounts = words.groupBy(\n",
    "#     window(words.timestamp, \"10 minutes\", \"5 minutes\"),\n",
    "#     words.word\n",
    "# ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crypto_agg_stream = (crypto_aggregation\n",
    "    .writeStream\n",
    "    .outputMode('append')\n",
    "    .queryName('crypto_agg')\n",
    "    .format('memory')\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|start|price|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df = spark.sql('select start, price from crypto_agg')\n",
    "crypto_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_agg_stream.stop()\n",
    "crypto_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the two streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+\n",
      "|              start|          sentiment|n_tweets|\n",
      "+-------------------+-------------------+--------+\n",
      "|2019-11-14 21:19:35|0.16271666666666665|       6|\n",
      "|2019-11-14 21:19:40| 0.2368888888888889|       9|\n",
      "|2019-11-14 21:19:45|0.14646666666666666|      12|\n",
      "|2019-11-14 21:19:50|          0.1613125|      16|\n",
      "|2019-11-14 21:19:55|0.15598695652173913|      23|\n",
      "|2019-11-14 21:20:00|0.19555185185185187|      27|\n",
      "|2019-11-14 21:20:05|            0.20652|      25|\n",
      "|2019-11-14 21:20:10|0.23004285714285716|      28|\n",
      "|2019-11-14 21:20:15|           0.272624|      25|\n",
      "|2019-11-14 21:20:25| 0.3045962962962963|      27|\n",
      "|2019-11-14 21:20:20|0.24680357142857146|      28|\n",
      "|2019-11-14 21:20:30| 0.2979185185185185|      27|\n",
      "+-------------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|start|price|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+------------------+\n",
      "|              start|          sentiment|n_tweets|             price|\n",
      "+-------------------+-------------------+--------+------------------+\n",
      "|2019-11-14 20:04:40|0.25397142857142857|       7|7850.0025000000005|\n",
      "|2019-11-14 20:03:45|0.20998965517241377|      29| 7848.673333333333|\n",
      "|2019-11-14 20:03:50| 0.1462103448275862|      29| 7848.803333333333|\n",
      "|2019-11-14 20:04:10|0.19134285714285718|      28|          7848.965|\n",
      "|2019-11-14 20:04:35| 0.3238230769230769|      13|          7849.938|\n",
      "|2019-11-14 20:04:05|             0.1619|      27|          7848.845|\n",
      "|2019-11-14 20:04:45|0.44444999999999996|       4| 7850.110000000001|\n",
      "|2019-11-14 20:04:50|0.44914999999999994|       2|           7850.35|\n",
      "|2019-11-14 20:03:15| 0.2464421052631579|      19|           7847.27|\n",
      "|2019-11-14 20:03:10|0.27543529411764706|      17|           7847.27|\n",
      "|2019-11-14 20:03:55|0.15807878787878787|      33| 7848.926666666666|\n",
      "|2019-11-14 20:03:30| 0.2130695652173913|      23| 7847.670000000001|\n",
      "|2019-11-14 20:03:40| 0.2160925925925926|      27| 7848.166666666667|\n",
      "|2019-11-14 20:03:20|0.25031363636363635|      22| 7847.266666666667|\n",
      "|2019-11-14 20:03:35|0.20973461538461538|      26| 7847.884999999999|\n",
      "|2019-11-14 20:04:25| 0.2845666666666667|      18|           7849.63|\n",
      "|2019-11-14 20:04:30|             0.3294|      14|          7849.895|\n",
      "|2019-11-14 20:04:00|0.16104687499999998|      32| 7848.724999999999|\n",
      "|2019-11-14 20:03:25| 0.2655818181818182|      22| 7847.275000000001|\n",
      "|2019-11-14 20:04:20|0.24600000000000002|      23|          7849.125|\n",
      "+-------------------+-------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.join(crypto_agg_df, 'start').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
