{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import window, avg, count\n",
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField, IntegerType, TimestampType, DoubleType\n",
    "from pyspark.sql.functions import from_json, col, to_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = SparkSession.builder.appName(\"Twitter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to twitter topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"E MMM dd HH:mm:ss +0000 yyyy\"\n",
    "\n",
    "# Create the schema of incoming data\n",
    "twitter_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('text', StringType(), False),\n",
    "    StructField('sentiment', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read kafka stream and subscribe to twitter topic\n",
    "twitter_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka-1:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'twitter')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), twitter_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "twitter_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter = twitter_df.select('value.*')\n",
    "twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_stream = (twitter\n",
    "         .writeStream\n",
    "         .queryName(\"twitter\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---------+\n",
      "|          timestamp|                text|sentiment|\n",
      "+-------------------+--------------------+---------+\n",
      "|2019-10-31 08:52:24|Yesterday results...|      0.0|\n",
      "|2019-10-31 08:52:25|RT @Cointelegraph...|      0.0|\n",
      "+-------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from twitter\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscribe to crypto topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the schema of incoming data\n",
    "crypto_schema = StructType([\n",
    "    StructField('timestamp', TimestampType(), False),\n",
    "    StructField('price', DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- timestamp: timestamp (nullable = true)\n",
      " |    |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the timestamp format\n",
    "timestampFormat = \"dd-mm-yyyy HH:mm:ss\"\n",
    "\n",
    "# Read kafka stream and subscribe to crypto topic\n",
    "crypto_df = (spark.readStream\n",
    "          .format('kafka')\n",
    "          .option('kafka.bootstrap.servers', 'kafka-1:9092')\n",
    "          .option('startingOffsets', 'latest')\n",
    "          .option('subscribe', 'crypto')\n",
    "          .load()\n",
    "          .select(col(\"key\").cast(\"string\"), \\\n",
    "                  from_json(col(\"value\").cast(\"string\"), crypto_schema, \\\n",
    "                  { \"timestampFormat\": timestampFormat }).alias(\"value\")))\n",
    "\n",
    "crypto_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto = crypto_df.select('value.*')\n",
    "crypto.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df_stream = (crypto\n",
    "         .writeStream\n",
    "         .queryName(\"crypto\")\n",
    "         .format(\"memory\")\n",
    "         .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|timestamp|price|\n",
      "+---------+-----+\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw = spark.sql(\"select * from crypto\")\n",
    "raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_aggregation = (twitter\n",
    "                     .groupBy(window(twitter.timestamp, '30 seconds'))\n",
    "                     .agg(avg('sentiment').alias('sentiment'), count('timestamp').alias('n_tweets')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweet_agg_stream = (tweet_aggregation\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .queryName(\"tweets_aggs\")\n",
    "    .format(\"memory\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- sentiment: double (nullable = true)\n",
      " |-- n_tweets: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from tweets_aggs\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+\n",
      "|start              |sentiment          |n_tweets|\n",
      "+-------------------+-------------------+--------+\n",
      "|2019-10-31 08:53:00|0.331532           |25      |\n",
      "|2019-10-31 08:52:30|0.10249473684210526|19      |\n",
      "+-------------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df = spark.sql(\"select window.start, sentiment, n_tweets from tweets_aggs\")\n",
    "tweet_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_agg_stream.stop()\n",
    "tweet_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crypto aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[start: timestamp, price: double]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_aggregation = (crypto\n",
    "                     .groupBy(window(crypto.timestamp, '30 seconds'))\n",
    "                     .agg(avg('price').alias('price'))\n",
    "                     .select(['window.start', 'price']))\n",
    "\n",
    "crypto_aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crypto_agg_stream = (crypto_aggregation\n",
    "    .writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .queryName(\"crypto_agg\")\n",
    "    .format(\"memory\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|start              |price  |\n",
      "+-------------------+-------+\n",
      "|2019-01-31 08:58:30|8184.05|\n",
      "|2019-01-31 08:59:30|8180.18|\n",
      "|2019-01-31 08:59:00|8181.29|\n",
      "|2019-01-31 09:00:00|8179.71|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df = spark.sql(\"select start, price from crypto_agg\")\n",
    "crypto_agg_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_agg_stream.stop()\n",
    "crypto_agg_stream.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the two streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------+\n",
      "|              start|           sentiment|n_tweets|\n",
      "+-------------------+--------------------+--------+\n",
      "|2019-10-30 20:07:00|             0.09854|      20|\n",
      "|2019-10-30 20:07:30|-0.02256190476190...|      21|\n",
      "|2019-10-30 20:06:30|  0.1661153846153846|      26|\n",
      "|2019-10-30 20:08:00| 0.18208461538461543|      13|\n",
      "+-------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|              start|  price|\n",
      "+-------------------+-------+\n",
      "|2019-01-30 20:10:00|8255.23|\n",
      "|2019-01-30 20:09:00|8252.86|\n",
      "|2019-01-30 20:08:00|8258.44|\n",
      "|2019-01-30 20:13:30|8267.39|\n",
      "|2019-01-30 20:08:30|8257.95|\n",
      "|2019-01-30 20:13:00| 8263.5|\n",
      "|2019-01-30 20:06:30|8258.71|\n",
      "|2019-01-30 20:09:30|8255.41|\n",
      "|2019-01-30 20:07:00|8257.89|\n",
      "|2019-01-30 20:07:30|8258.62|\n",
      "|2019-01-30 20:11:00|8258.62|\n",
      "|2019-01-30 20:11:30|8260.95|\n",
      "|2019-01-30 20:10:30|8255.58|\n",
      "|2019-01-30 20:12:30|8261.06|\n",
      "|2019-01-30 20:12:00|8261.08|\n",
      "|2019-01-30 20:14:00|8267.99|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crypto_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------+-----+\n",
      "|start|sentiment|n_tweets|price|\n",
      "+-----+---------+--------+-----+\n",
      "+-----+---------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_agg_df.join(crypto_agg_df, 'start').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
